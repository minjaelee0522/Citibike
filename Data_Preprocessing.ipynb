{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_df(df):\n",
    "    df1 = df.copy()\n",
    "    df1['starttime'] = pd.to_datetime(df1['starttime'], errors=\"coerce\")\n",
    "    df1['stoptime'] = pd.to_datetime(df1['stoptime'], errors=\"coerce\")\n",
    "    df1['start hour'] = df1['starttime'].dt.hour\n",
    "    df1['stop hour'] = df1['stoptime'].dt.hour\n",
    "    \n",
    "    df1[\"start date\"] = pd.to_datetime(df1['start date'], errors=\"coerce\")\n",
    "    df1[\"start_date\"] = df1[\"start date\"].dt.date\n",
    "    df1['start year'] = df1['start date'].dt.year\n",
    "    df1['start month'] = df1['start date'].dt.month\n",
    "    df1['start day'] = df1['start date'].dt.day\n",
    "    df1['start dayofweek'] = df1['start date'].dt.weekday+1   # Monday:1 ~ Sunday: 7\n",
    "    df1['Isweekday'] = [0 if 6<=x<=7 else 1 for x in df1['start dayofweek']]\n",
    "    df1['stop date'] = df1['start_date']\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_df(df):\n",
    "    # Define distance: if same start and end location, use average speed of 8.3mph to estimate distance.\n",
    "    # If different locations, calculate Manhattan distance between two stations\n",
    "    df['distance']=np.where(df['start station id'] == df['end station id'],df['tripduration']*8.3/3600, abs(df['start station longitude']-df['end station longitude'])*53+abs(df['start station latitude']-df['end station latitude'])*69)\n",
    "    \n",
    "    df_daily = df.groupby('start_date').agg({'tripduration':['count','mean'],'distance':'mean'}).reset_index()\n",
    "    df_daily.columns = ['start_date','trip per day','daily avg trip duration','daily avg distance']\n",
    "    df_daily_merged = df.merge(df_daily, how = 'left', on = 'start_date')\n",
    "    \n",
    "    df_hourly = df.groupby(['start station id','start hour']).agg({'tripduration':['count','mean'],'distance':'mean'}).reset_index()\n",
    "    df_hourly.columns = ['start station id','start hour','trip per hour','hourly avg trip duration','hourly avg distance']\n",
    "    df_hourly_merged = df_daily_merged.merge(df_hourly, how = 'left', on = ['start station id','start hour'])\n",
    "    df_hourly_eachday = df.groupby(['start station id','start_date','start hour']).\\\n",
    "    agg({'tripduration':['count','mean'],'distance':'mean'}).reset_index()\n",
    "    df_hourly_eachday.columns = ['start station id','start_date','start hour','trip per hour eachday',\n",
    "                                 'hourly avg trip duration eachday','hourly avg distance eachday']\n",
    "    df_hourly_eachday_merged = df_hourly_merged.merge(df_hourly_eachday, how = 'left',\n",
    "                                                      on = ['start station id','start_date','start hour'])\n",
    "    return df_hourly_eachday_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " def merged_bikecount(df):\n",
    "    checkout = df.groupby(['start station id','start_date','start hour'])['tripduration'].count().reset_index()\n",
    "    checkout.columns = ['start station id','start_date','start hour','checkout counts']\n",
    "    checkin = df.groupby(['end station id','stop date','stop hour'])[['tripduration']].count().reset_index()\n",
    "    checkin.columns=['end station id','stop date','stop hour','checkin counts']\n",
    "    start_end = pd.merge(checkout, checkin,  how='outer', left_on=['start station id','start_date','start hour'], \n",
    "                    right_on = ['end station id','stop date','stop hour'])\n",
    "    start_end['start station id'] = start_end['start station id'].fillna(start_end['end station id'])\n",
    "    start_end['start_date'] = start_end['start_date'].fillna(start_end['stop date'])\n",
    "    start_end['start hour'] = start_end['start hour'].fillna(start_end['stop hour'])\n",
    "    start_end['checkout counts'] = start_end['checkout counts'].fillna(0)\n",
    "    start_end['checkin counts'] = start_end['checkin counts'].fillna(0)\n",
    "    start_end = start_end.drop(['end station id','stop date','stop hour'],axis=1)\n",
    "    start_end.columns=['station id','date','hour','checkout counts','checkin counts']\n",
    "    start_end['total counts'] = start_end['checkout counts'] + start_end['checkin counts']\n",
    "    merged_start_end = pd.merge(df, start_end,  how='left', left_on=['start station id','start_date','start hour'], \n",
    "         right_on = ['station id','date','hour']).drop(['station id','date','hour'],axis = 1)\n",
    "    merged_start_end = pd.merge(merged_start_end, start_end,  how='left', left_on=['end station id','stop date','stop hour'], \n",
    "         right_on = ['station id','date','hour']).drop(['station id','date','hour'],axis = 1) \n",
    "    merged_start_end = merged_start_end.rename(columns={'checkout counts_x':'start station checkout counts',\n",
    "                                                    'checkin counts_x':'start station checkin counts',\n",
    "                                                    'total counts_x':'start station total counts', \n",
    "                                                    'checkout counts_y':'end station checkout counts',\n",
    "                                                    'checkin counts_y':'end station checkin counts',\n",
    "                                                    'total counts_y':'end station total counts'}) \n",
    "    return merged_start_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Monthly Datasets (Trip and Weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_csv_files_2019 = [('2019' + \"%.2d\" + '-citibike-tripdata.csv') % i for i in range(9, 13)]\n",
    "trip_csv_files_2020 = [('2020' + \"%.2d\" + '-citibike-tripdata.csv') % i for i in range(1, 9)]\n",
    "csv_files = trip_csv_files_2019 + trip_csv_files_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction 201909-citibike-tripdata.csv\n",
      "Data extraction 201910-citibike-tripdata.csv\n",
      "Data extraction 201911-citibike-tripdata.csv\n",
      "Data extraction 201912-citibike-tripdata.csv\n",
      "Data extraction 202001-citibike-tripdata.csv\n",
      "Data extraction 202002-citibike-tripdata.csv\n",
      "Data extraction 202003-citibike-tripdata.csv\n",
      "Data extraction 202004-citibike-tripdata.csv\n",
      "Data extraction 202005-citibike-tripdata.csv\n",
      "Data extraction 202006-citibike-tripdata.csv\n",
      "Data extraction 202007-citibike-tripdata.csv\n",
      "Data extraction 202008-citibike-tripdata.csv\n"
     ]
    }
   ],
   "source": [
    "# Read monthly Citi Bike trip data, apply some filters.\n",
    "# Randomly select 5% of each month trip data and save it as csv for each month. \n",
    "# Similar method used to make test data for machine learning validation.\n",
    "\n",
    "path = 'finaldata/'\n",
    "for i, csv in enumerate(csv_files):\n",
    "    df_trip = pd.read_csv(path+csv)\n",
    "    \n",
    "    # remove trips that are longer than 1 day \n",
    "    df_trip = df_trip.loc[df_trip['tripduration']<= 24*3600] \n",
    "    \n",
    "    # remove areas that are not in NYC\n",
    "    df_trip = df_trip.loc[(df_trip['start station latitude']>40) & (df_trip['start station latitude']<41)] \n",
    "    df_trip = df_trip.loc[(df_trip['end station latitude']>40) & (df_trip['end station latitude']<41)] \n",
    "    \n",
    "    # sampling 5% dataset\n",
    "    df_sample = df_trip.sample(frac=0.05, random_state = 42)\n",
    "    \n",
    "    # add custom features using self-defined functions\n",
    "    df_sample = time_df(df_sample)\n",
    "    df_sample = aggregate_df(df_sample)\n",
    "    df_sample = merged_bikecount(df_sample)\n",
    "    \n",
    "    df_sample.to_csv(csv[:6] + '-clean-sample.csv')\n",
    "    print('Data extraction ' + csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sample_tmp = time_df(df_sample)\n",
    "#df_sample_tmp = aggregate_df(df_sample_tmp)\n",
    "#df_sample_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkout = df_sample_tmp.groupby(['start station id','start date','start hour'])['tripduration'].count().reset_index()\n",
    "#checkout.columns = ['start station id','start date','start hour','checkout counts']\n",
    "#checkin = df_sample_tmp.groupby(['end station id','stop date','stop hour'])[['tripduration']].count().reset_index()\n",
    "#checkin.columns=['end station id','stop date','stop hour','checkin counts']\n",
    "#print(checkin.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_end = pd.merge(checkout, checkin,  how='outer', left_on=['start station id','start date','start hour'], \n",
    "                     #right_on = ['end station id','stop date','stop hour'])\n",
    "#start_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sample_list = []\n",
    "for i, csv in enumerate(csv_files):\n",
    "    clean_sample_list.append(csv[:6] + '-clean-sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 dataframe\n",
      "Completed 1 dataframe\n",
      "Completed 2 dataframe\n",
      "Completed 3 dataframe\n",
      "Completed 4 dataframe\n",
      "Completed 5 dataframe\n",
      "Completed 6 dataframe\n",
      "Completed 7 dataframe\n",
      "Completed 8 dataframe\n",
      "Completed 9 dataframe\n",
      "Completed 10 dataframe\n",
      "Completed 11 dataframe\n"
     ]
    }
   ],
   "source": [
    "# Merge all months clean_sample.csv into one clean_sample dataframe\n",
    "clean_sample_df = pd.DataFrame()\n",
    "for i in range(len(clean_sample_list)):\n",
    "    if csv.endswith('.csv'):\n",
    "        temp_df = pd.read_csv(clean_sample_list[i], index_col = 0)\n",
    "        clean_sample_df = pd.concat([clean_sample_df, temp_df], axis = 0)\n",
    "        print('Completed ' + str(i) + ' dataframe')\n",
    "clean_sample_df.to_csv('clean_sample.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
